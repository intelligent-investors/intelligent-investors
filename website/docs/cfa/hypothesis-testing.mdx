import FigureA from "./images/hypothesis-testing/figureA.png";
import FigureB from "./images/hypothesis-testing/figureB.png";

# Hypothesis Testing

This review addresses common hypothesis testing procedures. These procedures are used to conduct tests of population means, population variances, differences in means, differences in variances, and mean differences. Specific tests reviewed include the $z$-test, $t$-test, $\text{chi-square}$ test, and $F$-test. You should know when and how to apply each of these. A standard hypothesis testing procedure is utilized in this review. Know it! You should be able to perform a hypothesis test on the value of the mean without being given any formulas. Confidence intervals, levels of significance, the power of a test, and types of hypothesis testing errors are also discussed. Don‚Äôt worry about memorizing the messy formulas on testing for the equalities and differences in means and variances at the end of this review, but be able to interpret these statistics.

## 1: HYPOTHESIS TESTS AND TYPES OF ERRORS

Hypothesis testing is the statistical assessment of a statement or idea regarding a population. For instance, a statement could be as follows: ‚ÄúThe mean return for the U.S. equity market is greater than zero.‚Äù Given the relevant returns data, hypothesis testing procedures can be employed to test the validity of this statement at a given significance level.

### A: Define a hypothesis, describe the steps of hypothesis testing, and describe and interpret the choice of the null and alternative hypotheses.

A hypothesis is a statement about the value of a population parameter developed for the purpose of testing a theory or belief. Hypotheses are stated in terms of the population parameter to be tested, like the population mean, $$\mu$$. For example, a researcher may be interested in the mean daily return on stock options. Hence, the hypothesis may be that the mean daily return on a portfolio of stock options is positive.

Hypothesis testing procedures, based on sample statistics and probability theory, are used to determine whether a hypothesis is a reasonable statement and should not be rejected or if it is an unreasonable statement and should be rejected. The process of hypothesis testing consists of a series of steps shown in the following figure.

**Figure: Hypothesis Testing Procedure**

```mermaid
graph TD

A[State the hypothesis] --> B[Select the appropriate test statistic]
B --> C[Specify the level of significance]
C --> D[State the decision rule regarding the hypothesis]
D --> E[Collect the sample and calculate the sample statistics]
E --> F[Make a decision regarding the hypothesis]
F --> G[Make a decision based on the results of the test]
```

#### The Null Hypothesis and Alternative Hypothesis

**The null hypothesis**, designated $$H_0$$, is the hypothesis that the researcher wants to reject. It is the hypothesis that is actually tested and is the basis for the selection of the test statistics. The null is generally stated as a simple statement about a population parameter. Typical statements of the null hypothesis for the population mean include $$H_0: \mu = \mu_0$$, $$H_0: \mu \leq \mu_0$$, and $$H_0: \mu \geq \mu_0$$, where $$\mu$$ is the population mean and $$\mu_0$$ is the hypothesized value of the population mean.

:::note[**PROFESSOR‚ÄôS NOTE**]
The null hypothesis always includes the ‚Äúequal to‚Äù condition.
:::

The **alternative hypothesis**, designated $$H_a$$, is what is concluded if there is sufficient evidence to reject the null hypothesis. It is usually the alternative hypothesis that you are really trying to assess. Why? Since you can never really prove anything with statistics, when the null hypothesis is discredited, the implication is that the alternative hypothesis is valid.

### B: Distinguish between one-tailed and two-tailed tests of hypotheses.

The alternative hypothesis can be one-sided or two-sided. A one-sided test is referred to as a **one-tailed test**, and a two-sided test is referred to as a **two-tailed test**. Whether the test is one- or two-sided depends on the proposition being tested. If a researcher wants to test whether the return on stock options is greater than zero, a one-tailed test should be used. However, a two-tailed test should be used if the research question is whether the return on options is simply different from zero. Two-sided tests allow for deviation on both sides of the hypothesized value (zero). In practice, most hypothesis tests are constructed as two-tailed tests.

A **two-tailed test** for the population mean may be structured as:

$$
H_0: \mu = \mu_0 \text{ versus } H_a: \mu \neq \mu_0
$$

Since the alternative hypothesis allows for values above and below the hypothesized parameter, a two-tailed test uses two **critical values** (or **rejection points**).

The *general decision rule for a two-tailed test* is:

$$
\text{Reject } H_0 \text{ if:}
\begin{cases}
\text{test statistic } > \text{upper critical value} \\
\textbf{\textit{or}}\ \text{test statistic} < \text{lower critical value}
\end{cases}
$$

Let's look at the development of the decision rule for a two-tailed test using a z-distributed test statistic (z-test) at a 5\% level of significance, $\alpha = 0.05$.

- At $\alpha = 0.05$, the computed test statistic is compared with the critical z-values of $\pm 1.96$. The values of $\pm 1.96$ correspond to $z_{\alpha/2} = \pm z_{0.025}$, which is the range of z-values within which 95\% of the probability lies. These values are obtained from the cumulative probability table for the standard normal distribution (z-table), which is included at the back of this book.

- If the computed test statistic falls outside the range of critical z-values (i.e., test statistic $> 1.96$, or test statistic $< -1.96$), we reject the null and conclude that the sample statistic is sufficiently different from the hypothesized value.

- If the computed test statistic falls within the range $\pm 1.96$, we conclude that the sample statistic is not sufficiently different from the hypothesized value ($\mu = \mu_0$ in this case), and we fail to reject the null hypothesis.

The **decision rule** (rejection rule) *for a two-tailed z-test* at $\alpha = 0.05$ can be stated as:

$$
\text{Reject } H_0 \text{ if:}
\begin{cases}
\text{test statistic } > \text{1.96} \\
\textbf{\textit{or}}\ \text{test statistic} < \text{-1.96}
\end{cases}
$$

The following figure shows the standard normal distribution for a two-tailed hypothesis test using the z-distribution. Notice that the significance level of 0.05 means that there is 0.05 / 2 = 0.025 probability (area) under each tail of the distribution beyond $\pm 1.96$.

<div style={{ textAlign: 'center' }}>
<img src={FigureA} style={{width: 900}} />
</div>

For a **one-tailed hypothesis test** of the population mean, the null and alternative hypotheses are either:

$$
\begin{aligned}
* &\text{Upper tail: } & H_0: \mu \leq \mu_0 \ & \textbf{versus} & H_a: \mu > \mu_0 & \textit{, or} \\
* &\text{Lower tail: } & H_0: \mu \geq \mu_0 \ & \textbf{versus} & H_a: \mu < \mu_0 & \textit{.}
\end{aligned}
$$

The appropriate set of hypotheses depends on whether we believe the population mean, Œº, to be greater than (upper tail) or less than (lower tail) the hypothesized value, Œº‚ÇÄ. Using a z-test at the 5% level of significance, the computed test statistic is compared with the critical values of 1.645 for the upper tail tests (i.e., $$H_{a}: \mu > \mu_{0}$$) or -1.645 for lower tail tests (i.e., $$H_{a}: \mu < \mu_{0}$$). These critical values are obtained from a z-table, where $$-z_{0.05} = -1.645$$ corresponds to a cumulative probability equal to 5\%, and the $$z_{0.05} = 1.645$$ corresponds to a cumulative probability of 95\% (1 - 0.05).

Let‚Äôs use the upper tail test structure where $$H_{0}: \mu \leq \mu_{0}$$ and $$H_{a}: \mu > \mu_{0}$$.

- If the calculated test statistic is greater than 1.645, we conclude that the sample statistic is sufficiently greater than the hypothesized value. In other words, we reject the null hypothesis.
- If the calculated test statistic is less than 1.645, we conclude that the sample statistic is not sufficiently different from the hypothesized value, and we fail to reject the null hypothesis.

The following figure shows the standard normal distribution and the rejection region for a one-tailed test (upper tail) at the 5\% level of significance.

**Figure: One-Tailed Hypothesis Test Using the Standard Normal (z) Distribution**

<div style={{ textAlign: 'center' }}>
<img src={FigureB} style={{width: 900}} />
</div>

#### The Choice of the Null and Alternative Hypotheses

The most common null hypothesis will be an ‚Äúequal to‚Äù hypothesis. Combined with a ‚Äúnot equal to‚Äù alternative, this will require a two-tailed test. The alternative is often the hoped-for hypothesis. The null will include the ‚Äúequal to‚Äù sign and the alternative will include the ‚Äúnot equal to‚Äù sign. When the null is that a coefficient is equal to zero, we hope to reject it and show the significance of the relationship.

When the null is less than or equal to, the (mutually exclusive) alternative is framed as greater than, and a one-tail test is appropriate. If we are trying to demonstrate that a return is greater than the risk-free rate, this would be the correct formulation. We will have set up the null and alternative hypothesis so that rejection of the null will lead to acceptance of the alternative, our goal in performing the test. As with a two-tailed test, the null for a one-tailed test will include the ‚Äúequal to‚Äù sign (i.e., either ‚Äúgreater than or equal to‚Äù or ‚Äúless than or equal to‚Äù). The alternative will include the opposite sign to the null‚Äîeither ‚Äúless than‚Äù or ‚Äúgreater than.‚Äù

### C: Explain a test statistic, Type I and Type II errors, a significance level, and how significance levels are used in hypothesis testing.

Hypothesis testing involves two statistics: the test statistic calculated from the sample data and the critical value of the test statistic. The value of the computed test statistic relative to the critical value is a key step in assessing the validity of a hypothesis.

A test statistic is calculated by comparing the point estimate of the population parameter with the hypothesized value of the parameter (i.e., the value specified in the null hypothesis). With reference to our option return example, this means we are concerned with the difference between the mean return of the sample (i.e., $$ \bar{x} = 0.001 $$) and the hypothesized mean return (i.e., $$ H_0: \mu = 0 $$). As indicated in the following expression, the test statistic is the difference between the sample statistic and the hypothesized value, scaled by the standard error of the sample statistic.

$$
\text{test statistic} = \frac{\text{sample statistic} - \text{hypothesized value}}{\text{standard error of the sample statistic}}
$$

The standard error of the sample statistic is the adjusted standard deviation of the sample. When the sample statistic is the sample mean, $$ \bar{x} $$, the standard error of the sample statistic for sample size $$ n $$ is calculated as:

$$
\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}
$$

when the population standard deviation, $$ \sigma $$, is known, or

$$
s_{\bar{x}} = \frac{s}{\sqrt{n}}
$$

when the population standard deviation, $$ \sigma $$, is not known. In this case, it is estimated using the standard deviation of the sample, $$ s $$.

:::note[**PROFESSOR'S NOTE**]
Don't be confused by the notation here. A lot of the literature you will encounter in your studies simply uses the term $$ \sigma_{\bar{x}} $$ for the standard error of the test statistic, regardless of whether the population standard deviation or sample standard deviation was used in its computation.
:::

As you will soon see, a test statistic is a random variable that may follow one of several distributions, depending on the characteristics of the sample and the population. We will look at four distributions for test statistics: the t-distribution, the z-distribution (standard normal distribution), the chi-square distribution, and the F-distribution. The critical value for the appropriate test statistic‚Äîthe value against which the computed test statistic is compared‚Äîdepends on its distribution.

#### Type I and Type II Errors

Keep in mind that hypothesis testing is used to make inferences about the parameters of a given population on the basis of statistics computed for a sample that is drawn from that population. We must be aware that there is some probability that the sample, in some way, does not represent the population, and any conclusion based on the sample about the population may be made in error.

When drawing inferences from a hypothesis test, there are two types of errors:

- **Type I error**: the rejection of the null hypothesis when it is actually true.
- **Type II error**: the failure to reject the null hypothesis when it is actually false.

The **significance level** is the probability of making a Type I error (rejecting the null when it is true) and is designated by the Greek letter alpha ($$\alpha$$). For instance, a significance level of 5% ($$\alpha = 0.05$$) means there is a 5% chance of rejecting a true null hypothesis. When conducting hypothesis tests, a significance level must be specified in order to identify the critical values needed to evaluate the test statistic.

### D: Explain a decision rule, the power of a test, and the relation between confidence intervals and hypothesis tests.

The decision for a hypothesis test is to either reject the null hypothesis or fail to reject the null hypothesis. Note that it is statistically incorrect to say "accept" the null hypothesis; it can only be supported or rejected. The decision rule for rejecting or failing to reject the null hypothesis is based on the distribution of the test statistic. For example, if the test statistic follows a normal distribution, the decision rule is based on critical values determined from the standard normal distribution (z-distribution). Regardless of the appropriate distribution, it must be determined if a one-tailed or two-tailed hypothesis test is appropriate before a decision rule (rejection rule) can be determined.

A decision rule is specific and quantitative. Once we have determined whether a one- or two-tailed test is appropriate, the significance level we require, and the distribution of the test statistic, we can calculate the exact critical value for the test statistic. Then we have a decision rule of the following form: if the test statistic is (greater, less) than the value X, reject the null hypothesis.

#### The Power of a Test

While the significance level of a test is the probability of rejecting the null hypothesis when it is true, the power of a test is the probability of correctly rejecting the null hypothesis when it is false. The power of a test is actually one minus the probability of making a Type II error, or $$1 - P(\text{Type II error})$$. In other words, the probability of rejecting the null when it is false (power of the test) equals one minus the probability of not rejecting the null when it is false (Type II error). When more than one test statistic may be used, the power of the test for the competing test statistics may be useful in deciding which test statistic to use. Ordinarily, we wish to use the test statistic that provides the most powerful test among all possible tests.

The following figure shows the relationship between the level of significance, the power of a test, and the two types of errors.

**Figure: Type I and Type II Errors in Hypothesis Testing**

||True Condition   |True Condition|
|---------------|:----------------:|:-------------------:|
| **Decision**   | $$H_0$$ **is true**  | $$H_0$$ **is false** |
| Do not reject $$H_0$$ | Correct decision  | Incorrect decision <br/> **Type II error**|
| Reject $$H_0$$    | Incorrect decision<br/>**Type I error** <br/>*Significance level*, $$\alpha$$ <br/> =P(Type I error)| Correct decision<br/>*Power of the test* <br/> = $$1 - P(\text{Type II error})$$) | 

Sample size and the choice of significance level (Type I error probability) will together determine the probability of a Type II error. The relation is not simple, however, and calculating the probability of a Type II error in practice is quite difficult. Decreasing the significance level (probability of a Type I error) from 5% to 1%, for example, will increase the probability of failing to reject a false null (Type II error) and therefore reduce the power of the test. Conversely, for a given sample size, we can increase the power of a test only with the cost that the probability of rejecting a true null (Type I error) increases. For a given significance level, we can decrease the probability of a Type II error and increase the power of a test, only by increasing the sample size.

#### The Relation Between Confidence Intervals and Hypothesis Tests

A confidence interval is a range of values within which the researcher believes the true population parameter may lie.

A confidence interval is determined as:

$$
\left[ 
\begin{array}{c}
\text{sample} \\
\text{statistic} 
\end{array} 
- \left( 
\begin{array}{c}
\text{critical} \\
\text{value} 
\end{array} \right) 
\left( 
\begin{array}{c}
\text{standard} \\
\text{error} 
\end{array} \right) \right] 
\leq 
\begin{array}{c}
\text{population} \\
\text{parameter} 
\end{array} 
\leq \left[ 
\begin{array}{c}
\text{sample} \\
\text{statistic} 
\end{array} 
+ \left( 
\begin{array}{c}
\text{critical} \\
\text{value} 
\end{array} \right)
\left( 
\begin{array}{c}
\text{standard} \\
\text{error} 
\end{array} \right) \right]
$$

The interpretation of a confidence interval is that for a level of confidence of 95%, for example, there is a 95% probability that the true population parameter is contained in the interval.

From the previous expression, we see that a confidence interval and a hypothesis test are linked by the critical value. For example, a 95% confidence interval uses a critical value associated with a given distribution at the 5% level of significance. Similarly, a hypothesis test would compare a test statistic to a critical value at the 5% level of significance. To see this relationship more clearly, the expression for the confidence interval can be manipulated and restated as:

$$
-\text{{critical value}} \leq \text{{test statistic}} \leq +\text{{critical value}}
$$

This is the range within which we fail to reject the null for a two-tailed hypothesis test at a given level of significance.

:::info[**EXAMPLE**: Confidence intervals and two-tailed hypothesis tests]

A researcher has gathered data on the daily returns on a portfolio of call options over a recent 250-day period. The mean daily return has been 0.1\%, and the sample standard deviation of daily portfolio returns is 0.25\%. The researcher believes that the mean daily portfolio return is not equal to zero.

1. Construct a 95\% confidence interval for the population mean daily return over the 250-day sample period.
2. Construct a hypothesis test of the researcher's belief.

**Answer:**

1. Given a sample size of 250 with a standard deviation of 0.25\%, the standard error can be computed as 

$$
s_{\bar{x}} = \frac{s}{\sqrt{n}} = \frac{0.25}{\sqrt{250}} = 0.0158\%.
$$

At the 5\% level of significance, the critical z-values for the confidence interval are ¬±0.025 = 1.96 and ¬±0.025 = -1.96. Thus, given a sample mean equal to 0.1\%, the 95\% confidence interval for the population mean is:

$$
0.1 - 1.96(0.0158) \leq \mu \leq 0.1 + 1.96(0.0158)
$$

or

$$
0.069\% \leq \mu \leq 0.131\%.
$$

2. First we need to specify the null and alternative hypotheses. The null hypothesis is the one researcher expects to reject.

$$
H_0: \mu = 0 \text{ versus } H_a: \mu \neq 0
$$

Since the null hypothesis is an equality, this is a two-tailed test. At a 5\% level of significance, the critical z-values for a two-tailed test are ¬±1.96, so the decision rule can be stated as:

Reject $H_0$ if test statistic $<-1.96$ or test statistic $>+1.96$

Using the standard error of the sample mean we calculated above, our test statistic is:

$$
z = \frac{0.001 - 0}{0.00158} = 6.33
$$

Since 6.33 > 1.96, we reject the null hypothesis that the mean daily option return is equal to zero.

Notice the similarity of this analysis with our confidence interval. We rejected the hypothesis $\mu = 0$ because the sample mean of 0.1\% is more than 1.96 standard errors from zero. Based on the 95\% confidence interval, we reject $\mu = 0$ because zero is more than 1.96 standard errors from the sample mean of 0.1\%.
:::

### üìù QUIZ

1. To test whether the mean of a population is greater than 20, the appropriate null hypothesis is that the population mean is:

* A. less than 20.
* B. greater than 20.
* C. less than or equal to 20.

2. Which of the following statements about hypothesis testing is most accurate?

* A. A Type II error is rejecting the null when it is actually true.
* B. The significance level equals one minus the probability of a Type I error.
* C. A two-tailed test with a significance level of 5\% has z-critical values of $$\pm 1.96$$.

3. For a hypothesis test with a probability of a Type II error of 60\% and a probability of a Type I error of 5\%, which of the following statements is most accurate?

* A. The power of the test is 40\%, and there is a 5\% probability that the test statistic will exceed the critical value(s).
* B. There is a 95\% probability that the test statistic will be between the critical values if this is a two-tailed test.
* C. There is a 5\% probability that the null hypothesis will be rejected when actually true, and the probability of rejecting the null when it is false is 40\%.

4. If the significance level of a test is 0.05 and the probability of a Type II error is 0.15, what is the power of the test?

* A. 0.850.
* B. 0.950.
* C. 0.975.

## TESTS OF MEANS AND *p*-VALUES

### E: Distinguish between a statistical result and an economically meaningful result.

**Statistical significance** does not necessarily imply **economic significance**. For example, we may have tested a null hypothesis that a strategy of going long all the stocks that satisfy some criteria and shorting all the stocks that do not satisfy the criteria resulted in returns that were less than or equal to zero over a 20-year period. Assume we have rejected the null in favor of the alternative hypothesis that the returns to the strategy are greater than zero (positive). This does not necessarily mean that investing in that strategy will result in economically meaningful positive returns. Several factors must be considered.

One important consideration is transactions costs. Once we consider the costs of buying and selling the securities, we may find that the mean positive returns to the strategy are not enough to generate positive returns. Taxes are another factor that may make a seemingly attractive strategy a poor one in practice. A third reason that statistically significant results may not be economically significant is risk. In the above strategy, we have additional risk from short sales (they may have to be closed out earlier than in the test strategy). Since the statistically significant results were for a period of 20 years, it may be the case that there is significant variation from year to year in the returns from the strategy, even though the mean strategy return is greater than zero. This variation in returns from period to period is an additional risk to the strategy that is not accounted for in our test of statistical significance.

Any of these factors could make committing funds to a strategy unattractive, even though the statistical evidence of positive returns is highly significant. By the nature of statistical tests, a very large sample size can result in highly (statistically) significant results that are quite small in absolute terms.

### F: Explain and interpret the *p*-value as it relates to hypothesis testing.

The *p*-value is the probability of obtaining a test statistic that would lead to a rejection of the null hypothesis, assuming the null hypothesis is true. It is the smallest level of significance for which the null hypothesis can be rejected. For one-tailed tests, the *p*-value is the probability that lies above the computed test statistic for upper tail tests or below the computed test statistic for lower tail tests. For two-tailed tests, the *p*-value is the probability that lies above the positive value of the computed test statistic *plus* the probability that lies below the negative value of the computed test statistic.

Consider a two-tailed hypothesis test about the mean value of a random variable at the 95\% significance level where the test statistic is 2.3, greater than the upper critical value of 1.96. If we consult the Z-table, we find the probability of getting a value greater than 2.3 is (1 ‚Äì 0.9893) = 1.07\%. Since it‚Äôs a two-tailed test, our *p*-value is 2 √ó 1.07 = 2.14\%, as illustrated in *the following figure*. At a 3\%, 4\%, or 5\% significance level, we would reject the null hypothesis, but at a 2\% or 1\% significance level we would not. Many researchers report *p*-values without selecting a significance level and allow the reader to judge how strong the evidence for rejection is.

**Figure: Two-Tailed Hypothesis Test With *p*-Value = 2.14\%**

## KI·ªÇM TRA TRUNG B√åNH V√Ä *p*-GI√Å TR·ªä

### E: Ph√¢n bi·ªát gi·ªØa k·∫øt qu·∫£ th·ªëng k√™ v√† k·∫øt qu·∫£ c√≥ √Ω nghƒ©a kinh t·∫ø.

**√ù nghƒ©a th·ªëng k√™** kh√¥ng nh·∫•t thi·∫øt ƒë·ªìng nghƒ©a v·ªõi **√Ω nghƒ©a kinh t·∫ø**. V√≠ d·ª•, ch√∫ng ta c√≥ th·ªÉ ƒë√£ ki·ªÉm tra m·ªôt gi·∫£ thuy·∫øt kh√¥ng r·∫±ng m·ªôt chi·∫øn l∆∞·ª£c mua d√†i t·∫•t c·∫£ c√°c c·ªï phi·∫øu th·ªèa m√£n m·ªôt s·ªë ti√™u ch√≠ v√† b√°n ng·∫Øn t·∫•t c·∫£ c√°c c·ªï phi·∫øu kh√¥ng th·ªèa m√£n c√°c ti√™u ch√≠ ƒë√≥ ƒë√£ mang l·∫°i l·ª£i nhu·∫≠n nh·ªè h∆°n ho·∫∑c b·∫±ng kh√¥ng trong su·ªët 20 nƒÉm. Gi·∫£ s·ª≠ ch√∫ng ta ƒë√£ b√°c b·ªè gi·∫£ thuy·∫øt kh√¥ng ƒë·ªÉ ·ªßng h·ªô gi·∫£ thuy·∫øt thay th·∫ø r·∫±ng l·ª£i nhu·∫≠n t·ª´ chi·∫øn l∆∞·ª£c l·ªõn h∆°n kh√¥ng (d∆∞∆°ng). ƒêi·ªÅu n√†y kh√¥ng nh·∫•t thi·∫øt c√≥ nghƒ©a l√† ƒë·∫ßu t∆∞ v√†o chi·∫øn l∆∞·ª£c ƒë√≥ s·∫Ω mang l·∫°i l·ª£i nhu·∫≠n d∆∞∆°ng c√≥ √Ω nghƒ©a kinh t·∫ø. C·∫ßn ph·∫£i xem x√©t m·ªôt s·ªë y·∫øu t·ªë.

M·ªôt y·∫øu t·ªë quan tr·ªçng c·∫ßn xem x√©t l√† chi ph√≠ giao d·ªãch. Khi xem x√©t chi ph√≠ mua v√† b√°n ch·ª©ng kho√°n, ch√∫ng ta c√≥ th·ªÉ th·∫•y r·∫±ng l·ª£i nhu·∫≠n trung b√¨nh d∆∞∆°ng t·ª´ chi·∫øn l∆∞·ª£c kh√¥ng ƒë·ªß ƒë·ªÉ t·∫°o ra l·ª£i nhu·∫≠n d∆∞∆°ng. Thu·∫ø c≈©ng l√† m·ªôt y·∫øu t·ªë kh√°c c√≥ th·ªÉ l√†m cho m·ªôt chi·∫øn l∆∞·ª£c d∆∞·ªùng nh∆∞ h·∫•p d·∫´n tr·ªü n√™n k√©m hi·ªáu qu·∫£ trong th·ª±c t·∫ø. M·ªôt l√Ω do th·ª© ba khi·∫øn k·∫øt qu·∫£ c√≥ √Ω nghƒ©a th·ªëng k√™ c√≥ th·ªÉ kh√¥ng c√≥ √Ω nghƒ©a kinh t·∫ø l√† r·ªßi ro. Trong chi·∫øn l∆∞·ª£c tr√™n, ch√∫ng ta c√≥ th√™m r·ªßi ro t·ª´ vi·ªác b√°n kh·ªëng (ch√∫ng c√≥ th·ªÉ ph·∫£i ƒë√≥ng s·ªõm h∆°n so v·ªõi chi·∫øn l∆∞·ª£c ki·ªÉm tra). V√¨ k·∫øt qu·∫£ c√≥ √Ω nghƒ©a th·ªëng k√™ trong m·ªôt kho·∫£ng th·ªùi gian 20 nƒÉm, c√≥ th·ªÉ c√≥ s·ª± bi·∫øn ƒë·ªïi ƒë√°ng k·ªÉ t·ª´ nƒÉm n√†y sang nƒÉm kh√°c trong l·ª£i nhu·∫≠n t·ª´ chi·∫øn l∆∞·ª£c, m·∫∑c d√π l·ª£i nhu·∫≠n trung b√¨nh c·ªßa chi·∫øn l∆∞·ª£c l·ªõn h∆°n kh√¥ng. S·ª± bi·∫øn ƒë·ªïi n√†y trong l·ª£i nhu·∫≠n t·ª´ k·ª≥ n√†y sang k·ª≥ kh√°c l√† m·ªôt r·ªßi ro b·ªï sung cho chi·∫øn l∆∞·ª£c m√† kh√¥ng ƒë∆∞·ª£c t√≠nh ƒë·∫øn trong ki·ªÉm tra √Ω nghƒ©a th·ªëng k√™ c·ªßa ch√∫ng ta.

B·∫•t k·ª≥ y·∫øu t·ªë n√†o trong s·ªë n√†y c≈©ng c√≥ th·ªÉ l√†m cho vi·ªác cam k·∫øt ƒë·∫ßu t∆∞ v√†o m·ªôt chi·∫øn l∆∞·ª£c tr·ªü n√™n kh√¥ng h·∫•p d·∫´n, ngay c·∫£ khi b·∫±ng ch·ª©ng th·ªëng k√™ v·ªÅ l·ª£i nhu·∫≠n d∆∞∆°ng l√† r·∫•t ƒë√°ng k·ªÉ. Theo b·∫£n ch·∫•t c·ªßa c√°c ki·ªÉm tra th·ªëng k√™, m·ªôt c·ª° m·∫´u r·∫•t l·ªõn c√≥ th·ªÉ d·∫´n ƒë·∫øn k·∫øt qu·∫£ c√≥ √Ω nghƒ©a (th·ªëng k√™) cao m√† l·∫°i kh√° nh·ªè v·ªÅ m·∫∑t tuy·ªát ƒë·ªëi.

### F: Gi·∫£i th√≠ch v√† di·ªÖn gi·∫£i *p*-gi√° tr·ªã li√™n quan ƒë·∫øn ki·ªÉm tra gi·∫£ thuy·∫øt.

*p*-gi√° tr·ªã l√† x√°c su·∫•t nh·∫≠n ƒë∆∞·ª£c m·ªôt th·ªëng k√™ ki·ªÉm tra d·∫´n ƒë·∫øn vi·ªác b√°c b·ªè gi·∫£ thuy·∫øt kh√¥ng, gi·∫£ s·ª≠ gi·∫£ thuy·∫øt kh√¥ng l√† ƒë√∫ng. ƒê√¢y l√† m·ª©c ƒë·ªô nh·ªè nh·∫•t c·ªßa √Ω nghƒ©a m√† t·∫°i ƒë√≥ gi·∫£ thuy·∫øt kh√¥ng c√≥ th·ªÉ b·ªã b√°c b·ªè. ƒê·ªëi v·ªõi ki·ªÉm tra m·ªôt ph√≠a, *p*-gi√° tr·ªã l√† x√°c su·∫•t n·∫±m tr√™n th·ªëng k√™ ki·ªÉm tra ƒë√£ t√≠nh cho c√°c ki·ªÉm tra ph√≠a tr√™n ho·∫∑c d∆∞·ªõi th·ªëng k√™ ki·ªÉm tra ƒë√£ t√≠nh cho c√°c ki·ªÉm tra ph√≠a d∆∞·ªõi. ƒê·ªëi v·ªõi ki·ªÉm tra hai ph√≠a, *p*-gi√° tr·ªã l√† x√°c su·∫•t n·∫±m tr√™n gi√° tr·ªã d∆∞∆°ng c·ªßa th·ªëng k√™ ki·ªÉm tra ƒë√£ t√≠nh *c·ªông v·ªõi* x√°c su·∫•t n·∫±m d∆∞·ªõi gi√° tr·ªã √¢m c·ªßa th·ªëng k√™ ki·ªÉm tra ƒë√£ t√≠nh.

Xem x√©t m·ªôt ki·ªÉm tra gi·∫£ thuy·∫øt hai ph√≠a v·ªÅ gi√° tr·ªã trung b√¨nh c·ªßa m·ªôt bi·∫øn ng·∫´u nhi√™n ·ªü m·ª©c ƒë·ªô √Ω nghƒ©a 95\% n∆°i th·ªëng k√™ ki·ªÉm tra l√† 2.3, l·ªõn h∆°n gi√° tr·ªã t·ªõi h·∫°n ph√≠a tr√™n l√† 1.96. N·∫øu ch√∫ng ta tham kh·∫£o b·∫£ng Z, ch√∫ng ta s·∫Ω th·∫•y x√°c su·∫•t nh·∫≠n ƒë∆∞·ª£c gi√° tr·ªã l·ªõn h∆°n 2.3 l√† (1 ‚Äì 0.9893) = 1.07\%. V√¨ ƒë√¢y l√† ki·ªÉm tra hai ph√≠a, *p*-gi√° tr·ªã c·ªßa ch√∫ng ta l√† 2 √ó 1.07 = 2.14\%, nh∆∞ minh h·ªça trong *h√¨nh d∆∞·ªõi ƒë√¢y*. ·ªû m·ª©c ƒë·ªô √Ω nghƒ©a 3\%, 4\% ho·∫∑c 5\%, ch√∫ng ta s·∫Ω b√°c b·ªè gi·∫£ thuy·∫øt kh√¥ng, nh∆∞ng ·ªü m·ª©c ƒë·ªô √Ω nghƒ©a 2\% ho·∫∑c 1\% th√¨ kh√¥ng. Nhi·ªÅu nh√† nghi√™n c·ª©u b√°o c√°o *p*-gi√° tr·ªã m√† kh√¥ng ch·ªçn m·ª©c ƒë·ªô √Ω nghƒ©a v√† cho ph√©p ng∆∞·ªùi ƒë·ªçc ƒë√°nh gi√° m·ª©c ƒë·ªô m·∫°nh m·∫Ω c·ªßa b·∫±ng ch·ª©ng cho vi·ªác b√°c b·ªè.

**H√¨nh: Ki·ªÉm tra Gi·∫£ thuy·∫øt Hai ph√≠a V·ªõi *p*-Gi√° tr·ªã = 2.14\%**
